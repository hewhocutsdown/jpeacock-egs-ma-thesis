Spurious infinities: Hegel, Friendly AI, derivatives markets, Walter Benjamin on murder, Kant on murder, Eichmann on Kant, etc.
Friendly AI, derivatives, infinite information in a moment: the ethical decision and information theory

To some, the most pressing problem at hand is the development of an ethical system for an artificial intelligence which will come, and sooner than later. The usual term for this research project is "Friendly AI", as in "make the AI friendly to humanity before we make it infinitely smart and powerful." To the credit of pioneers like Eliezer Yudkowsky (of Less Wrong fame, and a founder of the Singularity Institute, now MIRI) and Nick Bostrom (founding director of the Future of Humanity Institute), these efforts have been sincere in the stated objective: to discover a means to ensure that the development of a superintelligence is made compatible with the continued survival of the entire human race.

It is to this end that Yudkowsky proposed the idea of coherent extrapolated volition:

    Our coherent extrapolated volition is our wish if we knew more, thought faster, were more the people we wished we were, had grown up farther together; where the extrapolation converges rather than diverges, where our wishes cohere rather than interfere; extrapolated as we wish that extrapolated, interpreted as we wish that interpreted.

In his book Superintelligence, Bostrom complicates the issue significantly when he muses:

    Does the extrapolition base include so-called "marginal persons" such as embryos, fetuses, brain-dead persons, patients with severe dementias or who are in permanent vegetative states? Does each of the hemispheres of a "split-brain" patient get its own weight in the extrapolation and is this weight the same as that of the entire brain of a normal subject? What about people who lived in the past but are now dead? People who will be born in the future? Higher animals and other sentient creatures? Digital minds? Extraterrestrials?

Bostrom's reductio ad absurdum notwithstanding, the entire success of a successful CEV rides on the possibility that collectively, our wishes about our wishes are not contradictory, and that humanity is homogeneous enough that a sample group will be sufficient to represent the volition of the entirety of the species. This isn't how the issue is discussed, however, with the stated objectives typically being framed in terms of the set of presently living humans. There is a possible trap here: our wishes, even our wishes about our wishes, are not unaffected by the wishes of others, and there's an infinite feedback process that fails to terminate. It's not merely a Zeno-style paradox, but it's an inherent constraint of the physical universe, as the information theoretic content of the CEV generation process approaches infinity.

Note to self:

https://plus.google.com/+JordanPeacock/posts/ASFatqdP4ny

https://plus.google.com/+JordanPeacock/posts/WQRqVDDNFa3